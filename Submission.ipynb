{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYP6PgOEzTa2"
      },
      "source": [
        "Dataset provided is of the following structure (only showing important parts):\n",
        "\n",
        "66e31d6ee96cd_student_resource_3/ <br/>\n",
        "├─ student_resource 3/ <br/>\n",
        "│  ├─ dataset/ <br/>\n",
        "│  │  ├─ sample_test <br/>\n",
        "│  │  ├─ sample_test_out <br/>\n",
        "│  │  ├─ sample_test_out_fail<br/>\n",
        "│  │  ├─ test <br/>\n",
        "│  │  ├─ train<br/>\n",
        "│  ├─ README<br/>\n",
        "│  ├─ src/<br/>\n",
        "│  │  ├─ utils.py<br/>\n",
        "│  │  ├─ sanity.py<br/>\n",
        "│  │  ├─ constants.py<br/>\n",
        "│  │  ├─ .DS_Store<br/>\n",
        "│  │  ├─ test.ipynb<br/>\n",
        "│  ├─ sample_code<br/>\n",
        "│  ├─ .DS_Store<br/>\n",
        "├─ __MACOSX/<br/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIGwOIxzzTa3"
      },
      "source": [
        "Extract Url Images for Test to Google Drive\n",
        "\n",
        "Steps:\n",
        "\n",
        "    1:  Upload the test.csv on the Colab Workspace (Not Google Drive)\n",
        "    2:  make sure you have necessary modules : request , tqdm\n",
        "\n",
        "you may then run the code below"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install timm"
      ],
      "metadata": {
        "id": "pL2NC3NF068a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrpANwoWzTa3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "save_folder = '/content/drive/MyDrive/Amazon_Hackathon_Images'\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "csv_file_path = 'test.csv'\n",
        "\n",
        "def download_images(csv_file, folder):\n",
        "    with open(csv_file, 'r') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in tqdm(reader):\n",
        "            image_url = row['image_link']\n",
        "            try:\n",
        "                response = requests.get(image_url, stream=True)\n",
        "                if response.status_code == 200:\n",
        "                    image_name = image_url.split(\"/\")[-1]\n",
        "                    image_path = os.path.join(folder, image_name)\n",
        "\n",
        "                    with open(image_path, 'wb') as f:\n",
        "                        for chunk in response.iter_content(1024):\n",
        "                            f.write(chunk)\n",
        "                else:\n",
        "                    print(f\"Failed to download {image_url}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading {image_url}: {str(e)}\")\n",
        "\n",
        "download_images(csv_file_path, save_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9VCIzvOzTa4"
      },
      "source": [
        "------------------------- Optional Code Begins -------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AkS8LexzTa4"
      },
      "source": [
        "NOTE : Optional part below\n",
        "\n",
        "Due to insufficient resources we had to run our inferences on multiple google colab accounts and to share the folder amongst them we have zipped it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT8AuxONzTa4"
      },
      "outputs": [],
      "source": [
        "!zip -r Images.zip /content/drive/MyDrive/Amazon_Hackathon_Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gopzhpxUzTa5"
      },
      "source": [
        "Then follow these steps:\n",
        "\n",
        "    1: Share the zip file with the other account\n",
        "    2: in the other account make a shortcut to this file in MyDrive\n",
        "\n",
        "the location to this zip file must be '/content/drive/MyDrive/Images.zip'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2Y3ehLDzTa5"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/Images.zip' -d 'Images'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXoSOXYAzTa5"
      },
      "source": [
        "this will successfully transfer the images to the Colab Workspace in the folder Images/Images/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfQGk0_rzTa5"
      },
      "source": [
        "-----------------------------Optional Part Ends ---------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_MK43IRzTa5"
      },
      "source": [
        "Note : in the optional code part we transfered all images to the Colab WorkSpace in Images/Images/ from now on we will consider this to be the folder to deal with\n",
        "\n",
        "If You Skip the Optional Code : Make sure to make this folder and mount and transfer all images to this folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajyS9UrZzTa6"
      },
      "source": [
        "Image cropping and enchancement\n",
        "\n",
        "    we have cropped the images from all side after carefully observing the data given\n",
        "\n",
        "    And after that we have applied image upscaling to 2x the original size\n",
        "\n",
        "simply following the code below will work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEQPe_XFzTa6"
      },
      "outputs": [],
      "source": [
        "# Image cropper\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def crop_image(image_path, left, top, right, bottom):\n",
        "    with Image.open(image_path) as img:\n",
        "        width, height = img.size\n",
        "        cropped_img = img.crop((left, top, width - right, height - bottom))\n",
        "        return cropped_img\n",
        "\n",
        "def process_images_in_folder(folder_path, left, top, right, bottom):\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            try:\n",
        "                cropped_img = crop_image(file_path, left, top, right, bottom)\n",
        "                cropped_img.save(file_path)\n",
        "                print(f\"Processed and saved: {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {str(e)}\")\n",
        "\n",
        "# Usage\n",
        "images_folder = \"Images/Images\"\n",
        "left_crop = 20\n",
        "top_crop = 20\n",
        "right_crop = 20\n",
        "bottom_crop = 20\n",
        "\n",
        "process_images_in_folder(images_folder, left_crop, top_crop, right_crop, bottom_crop)\n",
        "print(\"All images have been processed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI7hMBvhzTa6"
      },
      "outputs": [],
      "source": [
        "# image upscaling\n",
        "\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def upscale_images_in_folder(input_folder, output_folder, scale_factor):\n",
        "    # Create output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate over all files in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "            # Construct full file path\n",
        "            img_path = os.path.join(input_folder, filename)\n",
        "\n",
        "            # Read the image using OpenCV\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            if img is not None:\n",
        "                # Get new dimensions\n",
        "                new_width = int(img.shape[1] * scale_factor)\n",
        "                new_height = int(img.shape[0] * scale_factor)\n",
        "\n",
        "                # Resize the image (upscale)\n",
        "                upscaled_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "                # Save the upscaled image to the output folder\n",
        "                output_path = os.path.join(output_folder, filename)\n",
        "                cv2.imwrite(output_path, upscaled_img)\n",
        "\n",
        "                print(f\"Upscaled and saved: {output_path}\")\n",
        "            else:\n",
        "                print(f\"Failed to read image: {img_path}\")\n",
        "\n",
        "# Example usage\n",
        "input_folder = \"Images/Images\"  # Specify your input folder\n",
        "output_folder = \"Images2\"  # Specify where to save the upscaled images\n",
        "scale_factor = 2.0  # Scale factor (2.0 means double the size)\n",
        "\n",
        "upscale_images_in_folder(input_folder, output_folder, scale_factor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up InternVL for inference"
      ],
      "metadata": {
        "id": "APuteydg0eon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "# from decord import VideoReader, cpu\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "def build_transform(input_size):\n",
        "    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n",
        "    transform = T.Compose([\n",
        "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
        "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=MEAN, std=STD)\n",
        "    ])\n",
        "    return transform\n",
        "\n",
        "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
        "    best_ratio_diff = float('inf')\n",
        "    best_ratio = (1, 1)\n",
        "    area = width * height\n",
        "    for ratio in target_ratios:\n",
        "        target_aspect_ratio = ratio[0] / ratio[1]\n",
        "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
        "        if ratio_diff < best_ratio_diff:\n",
        "            best_ratio_diff = ratio_diff\n",
        "            best_ratio = ratio\n",
        "        elif ratio_diff == best_ratio_diff:\n",
        "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
        "                best_ratio = ratio\n",
        "    return best_ratio\n",
        "\n",
        "def dynamic_preprocess(image, min_num=1, max_num=4, image_size=896, use_thumbnail=False):\n",
        "    orig_width, orig_height = image.size\n",
        "    aspect_ratio = orig_width / orig_height\n",
        "\n",
        "    # calculate the existing image aspect ratio\n",
        "    target_ratios = set(\n",
        "        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
        "        i * j <= max_num and i * j >= min_num)\n",
        "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
        "\n",
        "    # find the closest aspect ratio to the target\n",
        "    target_aspect_ratio = find_closest_aspect_ratio(\n",
        "        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
        "\n",
        "    # calculate the target width and height\n",
        "    target_width = image_size * target_aspect_ratio[0]\n",
        "    target_height = image_size * target_aspect_ratio[1]\n",
        "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
        "\n",
        "    # resize the image\n",
        "    resized_img = image.resize((target_width, target_height))\n",
        "    processed_images = []\n",
        "    for i in range(blocks):\n",
        "        box = (\n",
        "            (i % (target_width // image_size)) * image_size,\n",
        "            (i // (target_width // image_size)) * image_size,\n",
        "            ((i % (target_width // image_size)) + 1) * image_size,\n",
        "            ((i // (target_width // image_size)) + 1) * image_size\n",
        "        )\n",
        "        # split the image\n",
        "        split_img = resized_img.crop(box)\n",
        "        processed_images.append(split_img)\n",
        "    assert len(processed_images) == blocks\n",
        "    if use_thumbnail and len(processed_images) != 1:\n",
        "        thumbnail_img = image.resize((image_size, image_size))\n",
        "        processed_images.append(thumbnail_img)\n",
        "    return processed_images\n",
        "\n",
        "def load_image(image_file, input_size=448, max_num=4):\n",
        "    image = Image.open(image_file).convert('RGB')\n",
        "    transform = build_transform(input_size=input_size)\n",
        "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
        "    pixel_values = [transform(image) for image in images]\n",
        "    pixel_values = torch.stack(pixel_values)\n",
        "    return pixel_values\n",
        "\n",
        "# If you want to load a model using multiple GPUs, please refer to the `Multiple GPUs` section.\n",
        "path = 'OpenGVLab/InternVL2-1B'\n",
        "model = AutoModel.from_pretrained(\n",
        "    path,\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    use_flash_attn=True,\n",
        "    trust_remote_code=True).eval().cuda()\n",
        "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True, use_fast=True)\n"
      ],
      "metadata": {
        "id": "DzyWJ5WW2HYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below is for mapping unit short foms to names"
      ],
      "metadata": {
        "id": "eytEya-G31j_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entity_unit_map = {\n",
        "    'width': {'centimetre':'cm', 'foot':'ft', 'inch':\"\\\"\", 'millimetre':'mm','metre':'m' , 'yard':'yard'},\n",
        "    'depth': {'centimetre':'cm', 'foot':'ft', 'inch':\"\\\"\",'millimetre':'mm', 'metre':'m ',  'yard':'yard'},\n",
        "    'height': {'centimetre':'cm', 'foot':'ft', 'inch':\"\\\"\",  'millimetre':'mm','metre':'m ', 'yard':'yard'},\n",
        "    'item_weight': {'gram':'g','kilogram':'kg','microgram':'µg','milligram':'mg','ounce':'oz','pound':'lb','ton':'t'},\n",
        "    'maximum_weight_recommendation': {'gram':'g','kilogram':'kg','microgram':'µg','milligram':'mg','ounce':'oz','pound':'lb','ton':'t'},\n",
        "    'voltage': {'kilovolt':'kV', 'millivolt':'mV', 'volt':'V'},\n",
        "    'wattage': {'kilowatt':'kW', 'watt':'W'},\n",
        "    'item_volume': {'centilitre':'cL','cubic foot':'ft³','cubic inch':'in³','cup':'cup','decilitre':'dL','fluid ounce':'fl oz','gallon':'US gal','imperial gallon':'UK gal','litre':'L','microlitre':'µL','millilitre':'mL','pint':'pint','quart':'quart'}\n",
        "}"
      ],
      "metadata": {
        "id": "KActKLWD3Xnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code makes Map for vocab of the feature to actual units and makes a pickle file for that"
      ],
      "metadata": {
        "id": "pUFuyZal4TiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entities=[]\n",
        "Dict={}\n",
        "for i in entity_unit_map:\n",
        "    entities+=[i]\n",
        "    Dict[i]={}\n",
        "    for k in entity_unit_map[i]:\n",
        "        Dict[i][k]=k\n",
        "        Dict[i][entity_unit_map[i][k]]=k\n",
        "print(Dict)\n",
        "import pickle\n",
        "with open('Map.pkl', 'wb') as file:\n",
        "    pickle.dump(Dict, file)"
      ],
      "metadata": {
        "id": "1ut4kup038oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the pickle file"
      ],
      "metadata": {
        "id": "wE2NgQkN4HTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('Map.pkl', 'rb') as file:\n",
        "    loaded_data = pickle.load(file)\n",
        "\n",
        "def getval(entity,text,loaded_data):\n",
        "    text=text.lower()\n",
        "    indexes=[]\n",
        "    # L=text.split()\n",
        "    L=text.split()\n",
        "    M=[]\n",
        "    for i in range(len(L)):\n",
        "        num=\"\"\n",
        "        check=True\n",
        "        j=0\n",
        "        while(check and j<len(L[i])):\n",
        "            try:\n",
        "                float(L[i][:j+1])\n",
        "                num+=L[i][j]\n",
        "                j+=1\n",
        "            except ValueError:\n",
        "                check=False\n",
        "        if(len(num)!=0):\n",
        "            M+=[num]\n",
        "            if(len(num)==len(L[i])):\n",
        "              continue\n",
        "            M+=[L[i][len(num):]]\n",
        "        else:\n",
        "            M+=[L[i]]\n",
        "    L=M\n",
        "    for i in range(len(L)):\n",
        "        try:\n",
        "            float(L[i])\n",
        "            indexes+=[i]\n",
        "        except ValueError:\n",
        "            continue\n",
        "    for i in indexes:\n",
        "        string=str(L[i+1:i+4])[2:-2]\n",
        "        for j in loaded_data[entity]:\n",
        "          p=j.lower()\n",
        "          k=p.split()\n",
        "          m=str(k)[2:-2]\n",
        "          if m == string[:len(m)]:\n",
        "              return L[i]+\" \"+loaded_data[entity][j]"
      ],
      "metadata": {
        "id": "-74xzE3q4AAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the pipeline for inference:"
      ],
      "metadata": {
        "id": "dBTTYPpNX8S2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "def dryrun(csvpath,i,j,imagesfolder,hop):\n",
        "  df=pd.read_csv(csvpath)\n",
        "  if 'prediction' in df.columns:\n",
        "    pass\n",
        "  else:\n",
        "    df['prediction']=[None]*len(df)\n",
        "  l=0\n",
        "  for k in range(i,j):\n",
        "    p=list(df.iloc[k,:])\n",
        "\n",
        "    impath=p[1][36:]\n",
        "    if(str(p[-1])!=\"nan\"):\n",
        "      continue\n",
        "    impath=os.path.join(imagesfolder,impath)\n",
        "    if os.path.exists(impath)==False:\n",
        "      print(impath)\n",
        "      continue\n",
        "    entity=p[3]\n",
        "    use = entity\n",
        "    if(entity == \"height\"):\n",
        "      use = \"vertical height\"\n",
        "    if(entity == \"depth\"):\n",
        "      use = \"vertical depth\"\n",
        "    if(entity == \"width\"):\n",
        "      use = \"horizontal width\"\n",
        "    if(entity == \"item_weight\"):\n",
        "      use = \"net item weight\"\n",
        "    if(entity == \"maximum_weight_recommendation\"):\n",
        "      use = \"maximum weight recommendation\"\n",
        "    if(entity == \"voltage\"):\n",
        "      use = \"mentioned voltage\"\n",
        "    # print(path)\n",
        "    pixel_values = load_image(impath, max_num=8).to(torch.float16).cuda()\n",
        "    generation_config = dict(max_new_tokens=4096, do_sample=False)\n",
        "    # question = f'<image>\\nImagine you are a product specialist. What would you report as the {use} of this item to a customer? Be precise and include units'\n",
        "    # question = f'<image>\\ntell in 2 line what is the {use} of product shown and only if {use} is explicitly written in two different units , then give me the imperial unit do not convert metric to imperial in any circumstance. Try to give only the needed {use} answer and not anything else'\n",
        "    question = f'<image>\\ntell in 1 line what is the {use} of product shown in the correct units given'\n",
        "    # question = f'<image>\\n1. Locate any text or labels related to {use}.\\n2. If found, report the exact value and unit.\\n3. If not found, estimate based on visual cues and clearly state it is an estimate.'\n",
        "\n",
        "\n",
        "    # question = f'<image>\\ntell me IN 3 LINES   ALL ABOUT\n",
        "\n",
        "    response = model.chat(tokenizer, pixel_values, question, generation_config, history=None, return_history=False)\n",
        "\n",
        "    # pattern = r\"(\\d+)-(\\d+)\\s*\"\n",
        "    first = \"\"\n",
        "    second =\"\"\n",
        "    third = \"\"\n",
        "    pattern = r\"(\\d+)-(\\d+)\\s*([a-zA-Z]+)\"\n",
        "\n",
        "    def replace_range_with_unit(match):\n",
        "          # Extract the range values and the unit\n",
        "          # lower_value = int(match.group(1))\n",
        "          # upper_value = int(match.group(2))\n",
        "          # first = lower_value\n",
        "          # second = upper_value\n",
        "          # unit = match.group(3)  # Capture the unit (e.g., \"V\", \"W\", \"Hz\")\n",
        "          # third = unit\n",
        "          # Return the formatted string as \"[lower_value, upper_value] unit\"\n",
        "          return \"\"\n",
        "\n",
        "      # Replace all occurrences of the pattern in the input string\n",
        "    result_str = re.sub(pattern, replace_range_with_unit, response)\n",
        "\n",
        "\n",
        "\n",
        "    def remove_common_prefix_suffix(str1, str2):\n",
        "      # Find the common prefix\n",
        "      min_len = min(len(str1), len(str2))\n",
        "      prefix_len = 0\n",
        "      while prefix_len < min_len and str1[prefix_len] == str2[prefix_len]:\n",
        "          prefix_len += 1\n",
        "\n",
        "      # Find the common suffix\n",
        "      suffix_len = 0\n",
        "      while suffix_len < min_len - prefix_len and str1[-(suffix_len + 1)] == str2[-(suffix_len + 1)]:\n",
        "          suffix_len += 1\n",
        "\n",
        "      # Extract the middle part (excluding common prefix and suffix)\n",
        "      middle_str1 = str1[prefix_len:len(str1) - suffix_len]\n",
        "      middle_str2 = str2[prefix_len:len(str2) - suffix_len]\n",
        "\n",
        "      return middle_str1, middle_str2\n",
        "\n",
        "    # Example usage\n",
        "    # str1 = \"The quick brown fox jumped over the lazy dog\"\n",
        "    # str2 = \"The quick brown cat jumped over the lazy dog\"\n",
        "\n",
        "\n",
        "    if(result_str != response):\n",
        "        unit_mapping = {\n",
        "            'V': 'volt',\n",
        "            'v': 'volt',\n",
        "            'volts': 'volt',\n",
        "            'mm': 'millimetre',\n",
        "            'MM': 'millimetre',\n",
        "            'm': 'metre',\n",
        "            'metres': 'metre',\n",
        "            'meter': 'metre',\n",
        "            'M': 'metre',\n",
        "            'cm': 'centimetre',\n",
        "            'CM': 'centimetre',\n",
        "            'centimeters': 'centimetre',\n",
        "            'kg': 'kilogram',\n",
        "            'KG': 'kilogram',\n",
        "            'kilograms': 'kilogram',\n",
        "            'G': 'gram',\n",
        "            'g': 'gram',\n",
        "            'grams': 'gram',\n",
        "            'yards':'yard',\n",
        "            '\\\"': 'inch',\n",
        "            'A': 'ampere',\n",
        "            'a': 'ampere',\n",
        "            'amperes': 'ampere',\n",
        "            'W': 'watt',\n",
        "            # 'w': 'watt',\n",
        "            'watts': 'watt',\n",
        "            'w': 'watt',\n",
        "            'Hz': 'hertz',\n",
        "            'hz': 'hertz'\n",
        "            # Add more units as needed\n",
        "        }\n",
        "        # print(\"result:\",result_str)\n",
        "        # print(\"response:\",response)\n",
        "\n",
        "        result_str1, result_str2 = remove_common_prefix_suffix(result_str, response)\n",
        "        # print(\"1:   \",result_str1)\n",
        "        # print(\"2:   \",result_str2)\n",
        "        ans = result_str2\n",
        "        if(ans == \"\"):\n",
        "          abs = result_str1\n",
        "\n",
        "        index = 0\n",
        "\n",
        "        ans.replace(\" \", \"\")\n",
        "\n",
        "        print(ans)\n",
        "        first = second = third = \"\"\n",
        "        found_dash = False\n",
        "        index = 0\n",
        "        check=False\n",
        "        # Loop through the string\n",
        "        for i in range(len(ans)):\n",
        "            if(check):\n",
        "              continue\n",
        "            # Check for the dash to split the parts\n",
        "            if ans[i] == \"-\":\n",
        "                first = ans[:i]\n",
        "                index = i + 1\n",
        "                found_dash = True\n",
        "                continue\n",
        "\n",
        "            # After finding the dash, split based on non-digit characters\n",
        "            if found_dash and (not ans[i].isdigit()):\n",
        "                second = ans[index:i]\n",
        "                third = ans[i:]\n",
        "                check=True\n",
        "        third = unit_mapping.get(third, third)\n",
        "        stri = f\"[{first}, {second}] {third}\"\n",
        "        df.iloc[k,-1]=stri\n",
        "        l+=1\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "    pattern = r\"(\\d+)(\\d+)/(\\d+)\\s*inches\"\n",
        "    pattern2 = r\"(\\d+)(\\d+)/(\\d+)\\s*\\\"\"\n",
        "\n",
        "    def replace_fraction(match):\n",
        "          # Extract the whole part, numerator, and denominator from the match\n",
        "          whole_number = int(match.group(1))  # First part of the number\n",
        "          numerator = int(match.group(2))     # Fraction numerator\n",
        "          denominator = int(match.group(3))   # Fraction denominator\n",
        "\n",
        "          # Compute the decimal equivalent\n",
        "          fractional_value = numerator / denominator\n",
        "          total_value = whole_number + fractional_value\n",
        "\n",
        "          # Return the formatted string with 2 decimal places\n",
        "          return f\"{total_value:.2f} inches\"\n",
        "\n",
        "\n",
        "\n",
        "    response = re.sub(pattern, replace_fraction, response)\n",
        "    response = re.sub(pattern2, replace_fraction, response)\n",
        "    # if \"in\" in response :\n",
        "\n",
        "    #   response = response.replace(\"in\", \"inches\")\n",
        "    # if \"inches\" in response and \"cm\" in response:\n",
        "    #   print(\"-----------------FOUND-------------------\")\n",
        "    #   response = response.replace(\"cm\", \"\")\n",
        "    # if \"in\" in response and \"cm\" in response:\n",
        "    #   print(\"-----------------FOUND-------------------\")\n",
        "    #   response = response.replace(\"cm\", \"\")\n",
        "\n",
        "    # if \"inches\" in response and \"mm\" in response:\n",
        "    #   print(\"-----------------FOUND-------------------\")\n",
        "    #   response = response.replace(\"mm\", \"\")\n",
        "    # if \"oz\" in response and \"g\" in response:\n",
        "    #   print(\"-----------------FOUND-------------------\")\n",
        "    #   response = response.replace(\"g\", \"\")\n",
        "    # if \"lb\" in response and \"g\" in response:\n",
        "    #   print(\"-----------------FOUND-------------------\")\n",
        "    #   response = response.replace(\"g\", \"\")\n",
        "\n",
        "\n",
        "    # return getval(entity,response,loaded_data)\n",
        "    df.iloc[k,-1]=getval(entity,response,loaded_data)\n",
        "    l+=1\n",
        "    if l%hop==0:\n",
        "      print(k)\n",
        "      df.to_csv(csvpath,index=False)\n",
        "  df.to_csv(csvpath,index=False)\n",
        "dryrun('/content/drive/MyDrive/Amazon_Test/test.csv',0,131188,'/content/Images/Images',20)"
      ],
      "metadata": {
        "id": "N2ep5a9wYDso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above stores the result in test.csv itself , This code helped us achieve a score of 0.53 initially so we have applied several augmentations"
      ],
      "metadata": {
        "id": "kLA_AW_i1fUt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentations:\n"
      ],
      "metadata": {
        "id": "-6MmJaFi1tap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Function to extract numeric value from prediction\n",
        "def extract_numeric_value(prediction):\n",
        "    match = re.search(r'\\d+\\.?\\d*', prediction)\n",
        "    return float(match.group()) if match else None\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('test0.csv')\n",
        "count = 0\n",
        "# Sort the dataframe by group_id and entity_name to ensure correct order\n",
        "# df = df.sort_values(by=['group_id', 'entity_name']).reset_index(drop=True)\n",
        "\n",
        "# Iterate through the DataFrame by pairs of consecutive rows\n",
        "for i in range(len(df) - 1):\n",
        "    # Check if consecutive rows have the same group_id\n",
        "    if df.loc[i, 'group_id'] == df.loc[i + 1, 'group_id']:\n",
        "        # Extract numeric values from the predictions\n",
        "        prediction_1 = df.loc[i, 'prediction']\n",
        "        prediction_2 = df.loc[i + 1, 'prediction']\n",
        "\n",
        "        # Check if the predictions are the same\n",
        "        if prediction_1 == prediction_2:\n",
        "            # print(df.loc[i, 'entity_name'])\n",
        "            if 'depth' == df.loc[i, 'entity_name']:\n",
        "                    count+=1\n",
        "                    df.loc[i, 'prediction'] = None\n",
        "            elif 'depth' == df.loc[i+1, 'entity_name']:\n",
        "                    count+=1\n",
        "                    df.loc[i + 1, 'prediction'] = None\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(df) - 1):\n",
        "    # Check if consecutive rows have the same group_id\n",
        "    if df.loc[i, 'group_id'] == df.loc[i + 1, 'group_id']:\n",
        "        # Extract numeric values from the predictions\n",
        "        prediction_1 = df.loc[i, 'prediction']\n",
        "        prediction_2 = df.loc[i + 1, 'prediction']\n",
        "\n",
        "        # Check if the predictions are the same\n",
        "        if prediction_1 == prediction_2:\n",
        "            # print(df.loc[i, 'entity_name'])\n",
        "            if 'height' == df.loc[i, 'entity_name']:\n",
        "                    count+=1\n",
        "                    df.loc[i, 'prediction'] = None\n",
        "            elif 'height' == df.loc[i+1, 'entity_name']:\n",
        "                    count+=1\n",
        "                    df.loc[i + 1, 'prediction'] = None\n",
        "\n",
        "            # Check if one row is 'depth' and the other is 'width'\n",
        "            # print(i)\n",
        "            # if()\n",
        "            # if ('depth' == df.loc[i, 'entity_name'] and 'width' == df.loc[i + 1, 'entity_name']) or ('width' == df.loc[i, 'entity_name'] and 'depth' == df.loc[i + 1, 'entity_name']):\n",
        "            #     # Remove the 'depth' prediction\n",
        "            #     print(\"rem\")\n",
        "            #     if 'depth' == df.loc[i, 'entity_name']:\n",
        "            #         df.loc[i, 'prediction'] = pd.NA\n",
        "            #     else:\n",
        "            #         df.loc[i + 1, 'prediction'] = pd.NA\n",
        "\n",
        "# Save the modified CSV\n",
        "print(count)\n",
        "df.to_csv('test0_without_depth_and_height.csv', index=False)\n",
        "\n",
        "print(\"Depth predictions removed where applicable.\")\n"
      ],
      "metadata": {
        "id": "g5mJfRlx1vWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "some other augmentations like promptings"
      ],
      "metadata": {
        "id": "KTUeih0d2ITj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9nVQvoNS2HpE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}